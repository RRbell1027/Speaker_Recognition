{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 這篇程式碼是用來訓練模型\n",
    "藉由輸入多名講者的資料集，讓模型學習如何分辨多名講者的聲音。<br>\n",
    "訓練 ResNet50 分類模型，然後刪除最後分類層。<br>\n",
    "如此便能得到生成**可辨識特定講者的聲音向量**的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sgyq4TwRHrx"
   },
   "outputs": [],
   "source": [
    "import os, librosa, random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 獲取浮點數組\n",
    "def _float_feature(value):\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "# 把數據添加到TFRecord中\n",
    "def data_example(data, label):\n",
    "    feature = {\n",
    "        'data': _float_feature(data),\n",
    "        'label': _int64_feature(label),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "\n",
    "'''\n",
    "將資料庫分成訓練集與測試集\n",
    "一則音頻隨機採樣 shards 段同秒數片段\n",
    "控制變數: 採樣秒數、梅爾頻譜輸出形狀(隨採樣秒數變更)、輸出數據檔檔名\n",
    "'''\n",
    "def create_data_tfrecord_by_random(data_path, save_path, shards):\n",
    "    data = []\n",
    "    for path in os.listdir(data_path):\n",
    "        data.append(os.listdir(data_path + path))\n",
    "    try:\n",
    "        os.remove(save_path)\n",
    "    except:\n",
    "        print('create {}',format(save_path))\n",
    "    with tf.io.TFRecordWriter(save_path) as writer:\n",
    "        for label, classpath in enumerate(data):\n",
    "            print('label: ' + str(label))\n",
    "            for i, path in enumerate(classpath):\n",
    "                print('sample: ' + str(i))\n",
    "                wav, sr = librosa.load(data_path + os.listdir(data_path)[label] + '/' + path, sr=22050)\n",
    "                intervals = librosa.effects.split(wav, top_db=20)\n",
    "                wav_output = []\n",
    "                intervals_wav = []\n",
    "                # [可能需要修改參數] 音頻長度 22050 * 秒數\n",
    "                wav_len = int(22050 * 5)\n",
    "                for sliced in intervals:\n",
    "                    intervals_wav.extend(wav[sliced[0]:sliced[1]])\n",
    "                flag = True\n",
    "                for i in range(shards):\n",
    "                    # 裁剪過長的音頻，過短的補0\n",
    "                    if len(intervals_wav) > wav_len:\n",
    "                        l = len(intervals_wav) - wav_len\n",
    "                        r = random.randint(0, l)\n",
    "                        wav_output = intervals_wav[r:wav_len + r]\n",
    "                    else:\n",
    "                        wav_output = np.concatenate((intervals_wav, np.zeros(shape=[wav_len - len(intervals_wav)], dtype=np.float32)))\n",
    "                    wav_output = np.array(wav_output)\n",
    "                    # 轉成梅爾頻譜\n",
    "                    ps = librosa.feature.mcff(y=wav_output, sr=sr, n_mels=128, hop_length=256).reshape(-1).tolist()\n",
    "                    if flag:\n",
    "                        print('shape: ', librosa.feature.mfcc(y=wav_output, sr=sr, n_mels=128, hop_length=256).shape)\n",
    "                        flag = False\n",
    "                    tf_example = data_example(ps, label)\n",
    "                    writer.write(tf_example.SerializeToString())\n",
    "                    if len(wav_output) <= wav_len:\n",
    "                        break\n",
    "\n",
    "'''\n",
    "將資料庫分成訓練集與測試集\n",
    "一則音頻每隔一定秒數取樣同時長片段\n",
    "控制變數: 間格秒數、採樣秒數、梅爾頻譜輸出形狀(隨採樣秒數變更)、輸出數據檔檔名\n",
    "'''\n",
    "def create_data_tfrecord_by_order(data_path, save_path):\n",
    "    data = []\n",
    "    for path in os.listdir(data_path):\n",
    "        data.append(os.listdir(data_path + path))\n",
    "    try:\n",
    "        os.remove(save_path)\n",
    "    except:\n",
    "        print('create {}'.format(save_path))\n",
    "    with tf.io.TFRecordWriter(save_path) as writer:\n",
    "        for label, classpath in enumerate(data):\n",
    "            print('label: ' + str(label))\n",
    "            for i, path in enumerate(classpath):\n",
    "                print('sample: ' + str(i))\n",
    "                wav, sr = librosa.load(data_path + os.listdir(data_path)[label] + '/' + path, sr=22050)\n",
    "                intervals = librosa.effects.split(wav, top_db=20)\n",
    "                intervals_wav = []\n",
    "                # [可能需要修改參數] 音頻長度 16000 * 秒數\n",
    "                wav_len = int(22050 * 5)\n",
    "                for sliced in intervals:\n",
    "                    intervals_wav.extend(wav[sliced[0]:sliced[1]])\n",
    "                l = len(intervals_wav) - wav_len\n",
    "                r = 0\n",
    "                flag = True\n",
    "                while r < l:\n",
    "                    wav_output = intervals_wav[r:wav_len + r]\n",
    "                    # [可能需要修改參數] 取樣間隔長度 22050 * 秒數\n",
    "                    r += int(22050 * 1)\n",
    "                    wav_output = np.array(wav_output)\n",
    "                    # 轉成梅爾頻譜\n",
    "                    ps = librosa.feature.mfcc(y=wav_output, sr=sr, n_mfcc=128, hop_length=256).reshape(-1).tolist()\n",
    "                    if flag:\n",
    "                        print('shape: ', librosa.feature.mfcc(y=wav_output, sr=sr, n_mfcc=128, hop_length=256).shape)\n",
    "                        flag = False\n",
    "                    tf_example = data_example(ps, label)\n",
    "                    writer.write(tf_example.SerializeToString())\n",
    "                    if len(wav_output) <= wav_len:\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JywYMIhIdBTx"
   },
   "outputs": [],
   "source": [
    "create_data_tfrecord_by_order('./source/train/', './data/mfcc_train.tfrecord')\n",
    "create_data_tfrecord_by_order('./source/test/', './data/mfcc_test.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6JPxnfRRYqs",
    "outputId": "e2476296-5e96-45f4-8276-696346ce6174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 4, None, 2048)     23558528  \n",
      "                                                                 \n",
      " activity_regularization (Ac  (None, 4, None, 2048)    0         \n",
      " tivityRegularization)                                           \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4, None, 2048)     0         \n",
      "                                                                 \n",
      " global_max_pooling (GlobalM  (None, 2048)             0         \n",
      " axPooling2D)                                                    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                102450    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,660,978\n",
      "Trainable params: 23,615,538\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class_dim = 50\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE= 32\n",
    "NAME = 'train_mfcc1'\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.applications.ResNet50V2(include_top=False, weights=None, input_shape=(128, None, 1)),\n",
    "    tf.keras.layers.ActivityRegularization(l2=0.5),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.GlobalMaxPooling2D(name='global_max_pooling'),\n",
    "    tf.keras.layers.Dense(units=class_dim, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 定義優化方法\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Td7TCI7DRWEi"
   },
   "outputs": [],
   "source": [
    "def _parse_data_function(example):\n",
    "    # [可能需要修改參數】 設置的梅爾頻譜的shape相乘的值\n",
    "    data_feature_description = {\n",
    "        'data': tf.io.FixedLenFeature([128*431], tf.float32),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    return tf.io.parse_single_example(example, data_feature_description)\n",
    "\n",
    "\n",
    "def train_reader_tfrecord(data_path, num_epochs, batch_size):\n",
    "    raw_dataset = tf.data.TFRecordDataset(data_path)\n",
    "    train_dataset = raw_dataset.map(_parse_data_function)\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1000) \\\n",
    "        .repeat(count=num_epochs) \\\n",
    "        .batch(batch_size=batch_size) \\\n",
    "        .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "def test_reader_tfrecord(data_path, batch_size):\n",
    "    raw_dataset = tf.data.TFRecordDataset(data_path)\n",
    "    test_dataset = raw_dataset.map(_parse_data_function)\n",
    "    test_dataset = test_dataset.batch(batch_size=batch_size)\n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_scTAYXqC3tQ"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_reader_tfrecord('./data/mfcc_train.tfrecord', EPOCHS, batch_size=BATCH_SIZE)\n",
    "test_dataset = test_reader_tfrecord('./data/mfcc_test.tfrecord', batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "moQz97j_1uni"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "try:\n",
    "  os.mkdir('./models/' + NAME + '/')\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n",
    "mylog = open('./logs/{}.log'.format(NAME), 'w')\n",
    "\n",
    "no_optim = 0\n",
    "\n",
    "train_epoch_loss = 0\n",
    "train_epoch_best_loss = 6\n",
    "for batch_id, data in enumerate(train_dataset):\n",
    "    # [可能需要修改參數】 設置的梅爾頻譜的shape\n",
    "    sounds = data['data'].numpy().reshape((-1, 128, 431, 1))\n",
    "    labels = data['label']\n",
    "    # 執行訓練\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(sounds)\n",
    "        # 獲取損失值\n",
    "        train_loss = tf.keras.losses.sparse_categorical_crossentropy(labels, predictions)\n",
    "        train_loss = tf.reduce_mean(train_loss)\n",
    "        # 獲取準確率\n",
    "        train_accuracy = tf.keras.metrics.sparse_categorical_accuracy(labels, predictions)\n",
    "        train_accuracy = np.sum(train_accuracy.numpy()) / len(train_accuracy.numpy())\n",
    "\n",
    "        train_epoch_loss = train_loss\n",
    "\n",
    "    #為避免過擬合，當損失值開始上升即時停損\n",
    "    if train_epoch_loss >= train_epoch_best_loss:\n",
    "        no_optim += 1\n",
    "    else:\n",
    "        no_optim = 0\n",
    "        train_epoch_best_loss = train_epoch_loss\n",
    "    if no_optim > 300:\n",
    "        if train_epoch_loss < 5e-1:\n",
    "            print('early stop at %d epoch' % batch_id, file=mylog)\n",
    "            print('early stop at %d epoch' % batch_id)\n",
    "            break\n",
    "    if no_optim > 100:\n",
    "        if train_epoch_loss < 5e-6:\n",
    "            print('early stop at %d epoch' % batch_id, file=mylog)\n",
    "            print('early stop at %d epoch' % batch_id)\n",
    "            break\n",
    "\n",
    "    # 更新梯度\n",
    "    gradients = tape.gradient(train_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    if batch_id % 20 == 0:\n",
    "        print(\"Batch %d, Loss %f, Accuracy %f\" % (batch_id, train_loss.numpy(), train_accuracy), file = mylog)\n",
    "        print(\"Batch %d, Loss %f, Accuracy %f\" % (batch_id, train_loss.numpy(), train_accuracy))\n",
    "    if batch_id % 100 == 0 and batch_id != 0:\n",
    "        test_losses = list()\n",
    "        test_accuracies = list()\n",
    "        for d in test_dataset:\n",
    "            # [可能需要修改參數】 設置的梅爾頻譜的shape\n",
    "            test_sounds = d['data'].numpy().reshape((-1, 128, 431, 1))\n",
    "            test_labels = d['label']\n",
    "\n",
    "            test_result = model(test_sounds)\n",
    "            # 獲取損失值\n",
    "            test_loss = tf.keras.losses.sparse_categorical_crossentropy(test_labels, test_result)\n",
    "            test_loss = tf.reduce_mean(test_loss)\n",
    "            test_losses.append(test_loss)\n",
    "            # 獲取準確率\n",
    "            test_accuracy = tf.keras.metrics.sparse_categorical_accuracy(test_labels, test_result)\n",
    "            test_accuracy = np.sum(test_accuracy.numpy()) / len(test_accuracy.numpy())\n",
    "            test_accuracies.append(test_accuracy)\n",
    "\n",
    "\n",
    "        print('=================================================', file = mylog)\n",
    "        print(\"Test, Loss %f, Accuracy %f\" % (\n",
    "            sum(test_losses) / len(test_losses), sum(test_accuracies) / len(test_accuracies)), file = mylog)\n",
    "        print('=================================================', file = mylog)\n",
    "\n",
    "        print('=================================================')\n",
    "        print(\"Test, Loss %f, Accuracy %f\" % (\n",
    "            sum(test_losses) / len(test_losses), sum(test_accuracies) / len(test_accuracies)))\n",
    "        print('=================================================')\n",
    "\n",
    "        # 保存模型\n",
    "        model.save(filepath='models/' + NAME + '/resnet.h5')\n",
    "        model.save_weights(filepath='models/' + NAME + '/model_weights.h5')\n",
    "mylog.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "聲紋辨識_mfcc.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
