{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 這篇程式碼是用來記錄一位講者的聲音向量\n",
    "藉由輸入特定講者的聲音資料集，利用已訓練的模型預測該講者的聲音向量。<br>\n",
    "把所有預測向量平均後儲存到後台，達到增加可辨識講者的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqazWqj4KGk-"
   },
   "outputs": [],
   "source": [
    "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4Df_uYueZvL"
   },
   "outputs": [],
   "source": [
    "import os, librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_audio(path):\n",
    "    # 載入輸入音檔\n",
    "    wav, sr = librosa.load(path, sr=22050)\n",
    "    intervals = librosa.effects.split(wav, top_db=20)\n",
    "    # 去掉無聲片段\n",
    "    wav_output = []\n",
    "    for sliced in intervals:\n",
    "        wav_output.extend(wav[sliced[0]:sliced[1]])\n",
    "    wav_output = np.array(wav_output)\n",
    "    return wav_output, sr\n",
    "\n",
    "def load_model(model_path):\n",
    "    # 載入模型，取模型最後第二層為輸出向量(拔掉全連接層)\n",
    "    # 2/23前的模型，layer名稱沒固定，如果發生錯誤請自行修改一下(記得改回來)\n",
    "    layer_name = 'global_max_pooling'\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    return tf.keras.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    \n",
    "def expect_prediction(data_path, model):\n",
    "    # 計算預測向量\n",
    "    feature = []\n",
    "    for audio in tqdm(os.listdir(data_path)):\n",
    "        # 載入音檔並轉成梅爾頻譜\n",
    "        wav_output, sr = load_audio(os.path.join(data_path, audio))\n",
    "        data = librosa.feature.mfcc(y=wav_output, sr=sr, n_mfcc=128, hop_length=256).astype(np.float32)\n",
    "        data = data[np.newaxis, ..., np.newaxis]\n",
    "        # 儲存預測向量\n",
    "        feature.append(model.predict(data))\n",
    "    # 返回預測向量之平均\n",
    "    return np.mean(np.array(feature), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkFYZi56-yrf"
   },
   "outputs": [],
   "source": [
    "model = load_model('./models/train_mfcc1/resnet.h5')\n",
    "feature2 = expect_prediction('./source/test/Speaker0', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whgeThcMN-hz"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "NAME = 'cmp_mcff1'\n",
    "log = open('./logs/{}.log'.format(NAME), 'w')\n",
    "for path in os.listdir('./source/test/'):\n",
    "    wav_input, sr = load_audio('./source/test/{}/{}_1.wav'.format(path, path))\n",
    "    data = librosa.feature.mfcc(y=wav_input, sr=sr, n_mfcc=128, hop_length=256).astype(np.float32)\n",
    "    data = data[np.newaxis, ..., np.newaxis]\n",
    "    feature1 = model.predict(data)\n",
    "    dist = np.dot(feature1[0], feature2[0]) / (np.linalg.norm(feature1[0]) * np.linalg.norm(feature2[0]))\n",
    "    dist = 1 - math.acos(dist) * 2 / math.pi\n",
    "    print('Speaker0 與 {} 相似度為: {}'.format(path, dist), file = log)\n",
    "    print('Speaker0 與 {} 相似度為: {}'.format(path, dist))\n",
    "log.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO3tJeRugebBgIfSzbmqg+E",
   "collapsed_sections": [],
   "name": "聲紋辨識_cmp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
